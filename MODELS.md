# Models

> Models larger than 10B don't fit with our GPUs (24 GB limited VRAM space)!

1. [facebook/opt-125m](https://huggingface.co/facebook/opt-125m), 125M
2. [openai/circuit-sparsity](https://huggingface.co/openai/circuit-sparsity), 400M
3. [Qwen/Qwen3-0.6B](https://huggingface.co/Qwen/Qwen3-0.6B), 800M
4. [ibm-granite/granite-4.0-h-1b](https://huggingface.co/ibm-granite/granite-4.0-h-1b), 1B
5. [ibm-granite/granite-4.0-micro](https://huggingface.co/ibm-granite/granite-4.0-micro), 3B
6. [google/gemma-2b](https://huggingface.co/google/gemma-2b), 3B
7. [ibm-granite/granite-4.0-h-tiny](https://huggingface.co/ibm-granite/granite-4.0-h-tiny), 7B
8. [meta-llama/Llama-3.1-8B-Instruct](https://huggingface.co/meta-llama/Llama-3.1-8B-Instruct), 8B
9. [ibm-granite/granite-3.3-8b-instruct](https://huggingface.co/ibm-granite/granite-3.3-8b-instruct), 8B
10. [Qwen/Qwen3-8B](https://huggingface.co/Qwen/Qwen3-8B), 8B
11. [google/gemma-2-9b](https://huggingface.co/google/gemma-2-9b), 9B
12. [google/recurrentgemma-9b-it](https://huggingface.co/google/recurrentgemma-9b-it), 10B
