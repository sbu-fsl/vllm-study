## NOTE: This file is template for model values configuration.
## Please create a copy of this file and fill in the values accordingly.

# namespace configs
namespace: llm-servings

# model configs
configs:
  name: ??
  serve:
    - >
      vllm serve ??
      --host 0.0.0.0
      --port 8000
      --tensor-parallel-size 1
      --no-enable-prefix-caching
      --trust-remote-code
      --seed 0
      --gpu-memory-utilization 0.95
      --max-model-len ??

# gpu configs
# RTX A5000 with 24.5 GB of VRAM (1) / Quadro 6000 with 24.5 GB of VRAM (2)
gpu:
  type: "??" # must be a5000 or q6000

# storage configs
storage:
  type: "??" # must be local or gpfs
